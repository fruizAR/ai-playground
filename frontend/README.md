# Frontend - OpenAI Chat Assistant

Aplicaci√≥n Angular para interactuar con el backend de orquestaci√≥n OpenAI con soporte de streaming en tiempo real.

## üöÄ Caracter√≠sticas

- ‚úÖ **Interfaz de chat intuitiva** - UI moderna y responsiva
- ‚úÖ **Streaming en tiempo real** - Respuestas usando Server-Sent Events (SSE)
- ‚úÖ **Renderizado Markdown** - Soporte completo para Markdown en respuestas
- ‚úÖ **Modo sin streaming** - Respuestas completas en una sola petici√≥n
- ‚úÖ **Configuraci√≥n ajustable** - Temperature y Max Tokens personalizables
- ‚úÖ **Estado del backend** - Indicador de conexi√≥n con el servicio
- ‚úÖ **Manejo de errores** - Gesti√≥n robusta de errores y estados de carga
- ‚úÖ **Historial de chat** - Guarda todas las conversaciones durante la sesi√≥n

## üìã Requisitos

- Node.js 18.x o superior
- npm 9.x o superior
- **Backend** - Uno de los siguientes:
  - Python FastAPI en `http://localhost:8000` (por defecto)
  - .NET ASP.NET Core en `https://localhost:7001/api/chat`

## üîß Instalaci√≥n

1. **Instalar dependencias:**

```bash
cd frontend
npm install
```

**Dependencias principales:**

- `@angular/core`: Framework Angular
- `ngx-markdown`: Renderizado de Markdown
- `marked`: Parser de Markdown
- `rxjs`: Programaci√≥n reactiva

## ‚ñ∂Ô∏è Ejecuci√≥n

**Modo desarrollo:**

```bash
npm start
# o
ng serve
```

La aplicaci√≥n estar√° disponible en `http://localhost:4200`

**Modo producci√≥n:**

```bash
npm run build
# Los archivos compilados estar√°n en dist/openai-chat
```

## üèóÔ∏è Estructura del Proyecto

```
frontend/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ chat/
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ chat.component.ts      # L√≥gica del componente
‚îÇ   ‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ chat.component.html    # Template HTML
‚îÇ   ‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ chat.component.css     # Estilos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ openai.service.ts          # Servicio HTTP
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ chat.models.ts             # Interfaces TypeScript
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app.module.ts                  # M√≥dulo principal
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ app.component.ts               # Componente ra√≠z
‚îÇ   ‚îú‚îÄ‚îÄ environments/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ environment.ts                 # Config desarrollo
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ environment.prod.ts            # Config producci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ index.html                         # HTML principal
‚îÇ   ‚îú‚îÄ‚îÄ main.ts                            # Bootstrap de Angular
‚îÇ   ‚îî‚îÄ‚îÄ styles.css                         # Estilos globales
‚îú‚îÄ‚îÄ angular.json                           # Configuraci√≥n Angular CLI
‚îú‚îÄ‚îÄ package.json                           # Dependencias npm
‚îî‚îÄ‚îÄ tsconfig.json                          # Configuraci√≥n TypeScript
```

## üé® Caracter√≠sticas del Componente Chat

### Configuraci√≥n

- **Streaming toggle**: Activa/desactiva el modo streaming
- **Temperature**: Control de creatividad (0.0 - 2.0)
- **Max Tokens**: L√≠mite de tokens en la respuesta (100 - 2000)

### Funcionalidades

1. **Env√≠o de mensajes**:

   - Enter para enviar
   - Shift+Enter para nueva l√≠nea

2. **Visualizaci√≥n en tiempo real**:

   - Con streaming: los caracteres aparecen a medida que se generan
   - Sin streaming: la respuesta completa aparece cuando est√° lista

3. **Indicadores visuales**:

   - üü¢ Conectado / üî¥ Desconectado
   - Indicador de streaming activo
   - Spinner de carga para modo sin streaming

4. **Historial**:
   - Bot√≥n para limpiar el chat
   - Timestamps en cada mensaje
   - Auto-scroll al √∫ltimo mensaje

## üîå Integraci√≥n con el Backend

El servicio `OpenAIService` maneja todas las comunicaciones:

```typescript
// Streaming
this.openAIService
  .askWithStreaming(request)
  .subscribe((chunk) => console.log(chunk));

// Sin streaming
this.openAIService
  .askWithoutStreaming(request)
  .subscribe((response) => console.log(response));

// Status del backend
this.openAIService.getStatus().subscribe((status) => console.log(status));
```

## üéØ Endpoints Utilizados

### Backend Python (FastAPI)

- `POST /ask` - Enviar prompts (streaming y no-streaming)
- `GET /status` - Estado del servicio backend
- `GET /logs` - Logs del sistema

### Backend .NET (ASP.NET Core)

- `POST /api/chat/ask` - Enviar prompts (streaming y no-streaming)
- `GET /api/chat/status` - Estado del servicio backend

## üåç Cambiar entre Backends

### Usar Backend Python (FastAPI)

Edita `src/environments/environment.ts`:

```typescript
export const environment = {
  production: false,
  apiUrl: "http://localhost:8000", // Python FastAPI
};
```

Ejecuta el backend Python:

```bash
cd backend
python run.py
```

### Usar Backend .NET (ASP.NET Core)

Edita `src/environments/environment.ts`:

```typescript
export const environment = {
  production: false,
  apiUrl: "https://localhost:7001/api/chat", // .NET ASP.NET Core
};
```

Ejecuta el backend .NET:

```bash
cd netcore/services
dotnet run
```

**Nota**: Ambos backends son 100% compatibles con el frontend. El streaming funciona igual en ambos.

## üé® Personalizaci√≥n

### Colores

Los colores principales est√°n definidos en `chat.component.css`:

```css
/* Gradiente principal */
linear-gradient(135deg, #667eea 0%, #764ba2 100%)

/* Puedes cambiarlos seg√∫n tus preferencias */
```

### Estilos

Modifica `src/styles.css` para cambios globales.

## üß™ Pruebas

```bash
npm test
# Ejecuta las pruebas unitarias con Karma
```

## üì¶ Build para Producci√≥n

```bash
npm run build
# Genera archivos optimizados en dist/openai-chat
```

Luego puedes servir los archivos con cualquier servidor web:

```bash
# Ejemplo con Python
cd dist/openai-chat
python -m http.server 8080
```

## üîç Troubleshooting

### Error de CORS

Si ves errores de CORS, verifica que el backend tenga configurado:

```python
allow_origins=["http://localhost:4200"]
```

### Backend no conecta

1. Verifica que el backend est√© corriendo en `http://localhost:8000`
2. Revisa la configuraci√≥n en `environment.ts`
3. Mira la consola del navegador para m√°s detalles

### Streaming no funciona

1. Verifica que el backend soporte SSE
2. Revisa que el endpoint `/ask` devuelva `Content-Type: text/event-stream`
3. Aseg√∫rate de que el navegador soporte EventSource API

### Markdown no se renderiza

1. Verifica que `ngx-markdown` est√© instalado: `npm install`
2. Aseg√∫rate de que `MarkdownModule` est√© importado en `app.module.ts`
3. Revisa los estilos de markdown en `chat.component.css`

## üìù Notas

- El componente usa `FormsModule` para two-way binding con `[(ngModel)]`
- El streaming usa la Fetch API con ReadableStream
- **Markdown rendering** con `ngx-markdown` y `marked` para formateo rico
- Los estilos son responsive y funcionan en m√≥viles
- El proyecto usa Angular 17 standalone components compatible

## üìö Documentaci√≥n Adicional

- [MARKDOWN.md](MARKDOWN.md) - Gu√≠a completa de soporte Markdown

## üöÄ Pr√≥ximos Pasos

- [x] Implementar markdown rendering para las respuestas
- [x] A√±adir syntax highlighting para c√≥digo
- [ ] Agregar persistencia de conversaciones (localStorage)
- [ ] Implementar modo oscuro
- [ ] Agregar exportaci√≥n de conversaciones
- [ ] Implementar autenticaci√≥n de usuarios
